import json
from pathlib import Path
from typing import List, Dict
from src.entity.RAGDataProcessor import RAGDataProcessor
from src.entity.ProcessedChunk import ProcessedChunk
from src.entity.SimpleVectorStore import SimpleVectorStore

class TechEnglishRAGSystem:
    def __init__(self, chunks_path: str = "rag_chunks/processed_chunks.jsonl"):
        self.chunks_path = chunks_path
        self.vector_store = SimpleVectorStore()
        self.setup_rag_system()

    def setup_rag_system(self):
        """Configura o sistema RAG completo"""
        try:
            print("ðŸ”„ Configurando sistema RAG...")

            # Carrega chunks processados
            self.chunks = self._load_processed_chunks()

            if not self.chunks:
                print("âš ï¸  Nenhum chunk encontrado. Processando dados...")
                processor = RAGDataProcessor()
                self.chunks = processor.process_all_data()
                processor.save_processed_chunks(self.chunks)

            # Adiciona chunks ao vector store
            self.vector_store.add_chunks(self.chunks)

            print(f"âœ… Sistema RAG configurado com {len(self.chunks)} chunks")

        except Exception as e:
            print(f"âŒ Erro na configuraÃ§Ã£o do RAG: {e}")

    def _load_processed_chunks(self) -> List[ProcessedChunk]:
        """Carrega chunks processados"""
        chunks = []
        try:
            if Path(self.chunks_path).exists():
                with open(self.chunks_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        data = json.loads(line)
                        chunks.append(ProcessedChunk(
                            content=data['content'],
                            metadata=data['metadata'],
                            chunk_id=data['chunk_id'],
                            embedding=data.get('embedding')
                        ))
                print(f"ðŸ“‚ Carregados {len(chunks)} chunks do arquivo")
            else:
                print("ðŸ“‚ Arquivo de chunks nÃ£o encontrado")
        except Exception as e:
            print(f"âŒ Erro ao carregar chunks: {e}")
        return chunks

    def _setup_embedding_model(self):
        """Configura modelo de embeddings"""
        try:
            from sentence_transformers import SentenceTransformer
            return SentenceTransformer('all-MiniLM-L6-v2')
        except ImportError:
            print("âŒ SentenceTransformers nÃ£o instalado")
            return None

    def query_rag(self, question: str, context: str = "development", n_results: int = 5):
        """
        Consulta o sistema RAG para conteÃºdo relevante
        """
        try:
            if not self.vector_store:
                return {
                    'question': question,
                    'context_chunks': [],
                    'total_chunks_found': 0,
                    'error': 'Vector store nÃ£o inicializado'
                }

            # Busca no vector store
            results = self.vector_store.search(
                query=question,
                n_results=n_results,
                context_filter=context
            )

            return {
                'question': question,
                'context_chunks': results,
                'total_chunks_found': len(results),
                'success': True
            }

        except Exception as e:
            print(f"âŒ Erro na consulta RAG: {e}")
            return {
                'question': question,
                'context_chunks': [],
                'total_chunks_found': 0,
                'error': str(e),
                'success': False
            }

    def _format_rag_response(self, question: str, results) -> Dict:
        """Formata a resposta do RAG"""
        context_chunks = []

        for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
            context_chunks.append({
                'content': doc,
                'source': metadata.get('title', 'Unknown'),
                'technology': metadata.get('technology', 'Unknown'),
                'relevance_score': metadata.get('score', 0)
            })

        return {
            'question': question,
            'context_chunks': context_chunks,
            'total_chunks_found': len(context_chunks)
        }


